{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10287b1",
   "metadata": {},
   "source": [
    "## Data Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c664a3a",
   "metadata": {},
   "source": [
    "In this report, I will explain the details of how I wrangled the available data. The process invloved data gathering, assessing the data quality and structure and cleaning the data before analysing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1592523",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ca1c5",
   "metadata": {},
   "source": [
    "- There were 3 data required for this investigation, an image prediction data called **image_prediction_final** which was in url format containing information about dog breed predictions,  a **tweeter_achieve** in csv format containing dog ratings, dog age stage and other useful information, the third file is an extracted tweeted json file called **data_json** containing tweeter retweet and faourite counts among other useful information.\n",
    "\n",
    "- **image_prediction_final**: This file was extracted using the request python library and applying request.get method on the url link to programmatically access the information in the url, the tabs were separated by applying the sep = '\\t' function.\n",
    "\n",
    "- **tweeter_achieve**: This csv data was imported into the anaconda environment through upload and then imported into the python notebook using the pandas dataframe and applying the pd.read_csv method on the csv file.\n",
    "\n",
    "- **data_json**: Due to authentification issues, I was unable to query the twitter API directly, however I have included the apui query code that I would have used for the twitter API query if I had the right keys and token. To overcome this challenge, the twitter json data was provided by Udacity instructor. The provided data was a txt file, I read the files using readlines() method, opened an empty dataframe, then appended contents of the txt file to the empty dataframe, I then converted the resulting data into a dataframe by applying pd.DataFrame method on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c39db",
   "metadata": {},
   "source": [
    "### Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192d30f",
   "metadata": {},
   "source": [
    "I assessed the data visually and programatically and documented all my observations\n",
    "\n",
    "- **Visual Assessment**\n",
    "    - I loaded some of the data by applying the sample method and head method as appropriate to see data structures and contents, then idenitified and documented cleaning required\n",
    "\n",
    "- **Programmatic Assessment**\n",
    "    - I used the following functions for programmatically assessing the file structures\n",
    "        - shape\n",
    "        - isnull()\n",
    "        - value_counts()\n",
    "        - sum()\n",
    "        - info()\n",
    "        - describe()\n",
    "        - unique()\n",
    "        - sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f99c3",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166d7e2",
   "metadata": {},
   "source": [
    "- After documenting my observations, I fixed each of the data quality and data tidiness issues highlighted. There were 9 data quality issues and 4 data tidiness issues in total.\n",
    "\n",
    "- I used the DCT method for the cleaning process: Define, Code and Test\n",
    "\n",
    "    - To delete duplicated and unrequired columns, I used the drop method to delete affected columns.\n",
    "    - For columns with wrong data types, I changed the columns datatype using astype method and calling the appropriate data type in the method.\n",
    "    - To extract information from multiple columns into one column, I developed the appropriate functions and applied the functions on the new column name containing extracted information. I used this method to extract **dog age stage** and **dog breed**. The dog age stage contains the dog class\n",
    "    - To create a dog ratings column, I divided the dog ratings numerator column by dog ratings denominator column.\n",
    "    - I used join method to merge the 3 files to form a master file and saved as csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf8d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
